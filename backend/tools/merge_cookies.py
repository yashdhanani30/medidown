# tools/merge_cookies.py
import argparse
import time
from typing import List, Tuple, Dict

HEADER = """# Netscape HTTP Cookie File
# This file was generated by merge_cookies.py
# Format: domain\tinclude_subdomains\tpath\tsecure\texpiration\tname\tvalue
"""

def parse_cookie_line(line: str):
    parts = line.strip().split("\t")
    if len(parts) != 7:
        return None
    domain, include_sub, path, secure, expires, name, value = parts
    try:
        exp = int(expires)
    except Exception:
        exp = 2147483647
    return {
        "domain": domain.strip(),
        "include_subdomains": include_sub.strip().upper() in ("TRUE", "1", "YES"),
        "path": path or "/",
        "secure": secure.strip().upper() in ("TRUE", "1", "YES"),
        "expires": exp,
        "name": name,
        "value": value,
    }

def normalize_domain(d: str) -> str:
    d = (d or "").strip()
    if not d:
        return d
    # Ensure leading dot for compatibility
    return d if d.startswith(".") else "." + d

def key_for(c) -> Tuple[str, str, str]:
    return (c["domain"].lower(), c["path"] or "/", c["name"])

def better_cookie(a, b):
    # Prefer later expiry; if equal, prefer secure; then prefer non-empty value
    if a["expires"] != b["expires"]:
        return a if a["expires"] > b["expires"] else b
    if a["secure"] != b["secure"]:
        return a if a["secure"] else b
    if (a["value"] or "") != (b["value"] or ""):
        return a if (a["value"] or "") > (b["value"] or "") else b
    return a

def load_cookies(paths: List[str], domains: List[str]) -> Dict[Tuple[str, str, str], dict]:
    allow = [d.lower().lstrip(".") for d in (domains or [])]
    merged: Dict[Tuple[str, str, str], dict] = {}

    for p in paths:
        with open(p, "r", encoding="utf-8", errors="ignore") as f:
            for raw in f:
                s = raw.strip()
                if not s or s.startswith("#"):
                    continue
                c = parse_cookie_line(s)
                if not c:
                    continue
                c["domain"] = normalize_domain(c["domain"])  # normalize for consistency
                if allow:
                    dom = c["domain"].lstrip(".").lower()
                    if not any(dom == d or dom.endswith("." + d) for d in allow):
                        continue
                k = key_for(c)
                if k not in merged:
                    merged[k] = c
                else:
                    merged[k] = better_cookie(merged[k], c)
    return merged

def main():
    ap = argparse.ArgumentParser(description="Merge multiple Netscape cookies.txt files")
    ap.add_argument("--out", required=True, help="Output cookies.txt path")
    ap.add_argument("--domains", nargs="*", default=[], help="Restrict to these domains (e.g., facebook.com instagram.com)")
    ap.add_argument("inputs", nargs="+", help="Input cookies.txt files to merge")
    args = ap.parse_args()

    merged = load_cookies(args.inputs, args.domains)
    items = sorted(merged.values(), key=lambda c: (c["domain"].lower(), c["name"].lower(), c["path"]))

    with open(args.out, "w", encoding="utf-8") as f:
        f.write(HEADER)
        for c in items:
            line = "\t".join([
                c["domain"],
                "TRUE" if c["include_subdomains"] else "FALSE",
                c["path"] or "/",
                "TRUE" if c["secure"] else "FALSE",
                str(c["expires"] if isinstance(c["expires"], int) else 2147483647),
                c["name"],
                c["value"],
            ])
            f.write(line + "\n")

    print(f"Merged {len(args.inputs)} file(s) -> {args.out} ({len(items)} unique cookies)")

if __name__ == "__main__":
    main()